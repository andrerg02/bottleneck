 80%|███████████████████████████████████████████████████████████████████████████████████▏                    | 8/10 [59:47<14:56, 448.40s/it]
Fold 0 | Epochs: 499 | Best epoch: 251
Best train loss: 0.0124 | Best test loss: 0.4460
Fold 1 | Epochs: 499 | Best epoch: 451
Best train loss: 0.0143 | Best test loss: 0.4141
Fold 2 | Epochs: 499 | Best epoch: 450
Best train loss: 0.0115 | Best test loss: 0.4230
Fold 3 | Epochs: 499 | Best epoch: 483
Best train loss: 0.0153 | Best test loss: 0.3893
Fold 4 | Epochs: 499 | Best epoch: 311
Best train loss: 0.0159 | Best test loss: 0.4354
Fold 5 | Epochs: 499 | Best epoch: 480
Best train loss: 0.0143 | Best test loss: 0.4377
Fold 6 | Epochs: 499 | Best epoch: 498
Best train loss: 0.0157 | Best test loss: 0.4131
Fold 7 | Epochs: 499 | Best epoch: 488
Best train loss: 0.0057 | Best test loss: 0.4125
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/alunos/Dados/andre/cooperative-sheaves/neural-sheaf-diffusion/cooperative_sheaves/exp/run_synth.py", line 129, in <module>
    train_loss, best_test_loss = run_exp(wandb.config, train_loader, test_loader, fold)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alunos/Dados/andre/cooperative-sheaves/neural-sheaf-diffusion/cooperative_sheaves/exp/run_synth.py", line 58, in run_exp
    train_loss = train(model, optimizer, train_data)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alunos/Dados/andre/cooperative-sheaves/neural-sheaf-diffusion/cooperative_sheaves/exp/run_synth.py", line 25, in train
    loss.backward()
  File "/home/alunos/Dados/.pyenv/versions/hsnn/lib/python3.11/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home/alunos/Dados/.pyenv/versions/hsnn/lib/python3.11/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/alunos/Dados/.pyenv/versions/hsnn/lib/python3.11/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
