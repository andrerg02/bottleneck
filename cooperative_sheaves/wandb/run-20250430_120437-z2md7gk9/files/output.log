 60%|███████████████████████████████████████████████████████████████████████████████████████████▏                                                            | 6/10 [09:44<06:29, 97.35s/it]
Fold 0 | Epochs: 663 | Best epoch: 563
Test acc: 0.5114
Best val acc: 0.5241
Fold 1 | Epochs: 603 | Best epoch: 503
Test acc: 0.5267
Best val acc: 0.5249
Fold 2 | Epochs: 618 | Best epoch: 518
Test acc: 0.5226
Best val acc: 0.5215
Fold 3 | Epochs: 370 | Best epoch: 270
Test acc: 0.5053
Best val acc: 0.4991
Fold 4 | Epochs: 620 | Best epoch: 520
Test acc: 0.5094
Best val acc: 0.5187
Fold 5 | Epochs: 552 | Best epoch: 452
Test acc: 0.5063
Best val acc: 0.5118
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/alunos/Dados/andre/cooperative-sheaves/neural-sheaf-diffusion/cooperative_sheaves/exp/run.py", line 203, in <module>
    test_acc, best_val_acc, keep_running = run_exp(wandb.config, dataset, model_cls, fold)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alunos/Dados/andre/cooperative-sheaves/neural-sheaf-diffusion/cooperative_sheaves/exp/run.py", line 103, in run_exp
    train_loss, val_loss, tmp_test_loss] = test(model, data, fold)
                                           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alunos/Dados/andre/cooperative-sheaves/neural-sheaf-diffusion/cooperative_sheaves/exp/run.py", line 66, in test
    out = F.log_softmax(logits[mask[fold]], dim=1)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alunos/Dados/.pyenv/versions/hsnn/lib/python3.11/site-packages/torch/nn/functional.py", line 2220, in log_softmax
    def log_softmax(

KeyboardInterrupt
