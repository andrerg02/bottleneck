  0%|                                                                                                                                                                | 0/10 [00:00<?, ?it/s]
Data(x=[24492, 300], edge_index=[2, 186100], y=[24492], train_mask=[10, 24492], val_mask=[10, 24492], test_mask=[10, 24492], name='amazon_ratings', random_walk_pe=[24492, 0])
torch.Size([186100]) torch.Size([186100, 1])
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/alunos/Dados/andre/cooperative-sheaves/neural-sheaf-diffusion/cooperative_sheaves/exp/run.py", line 201, in <module>
    test_acc, best_val_acc, keep_running = run_exp(wandb.config, dataset, model_cls, fold)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alunos/Dados/andre/cooperative-sheaves/neural-sheaf-diffusion/cooperative_sheaves/exp/run.py", line 106, in run_exp
    train(model, optimizer, data, fold)
  File "/home/alunos/Dados/andre/cooperative-sheaves/neural-sheaf-diffusion/cooperative_sheaves/exp/run.py", line 43, in train
    out = model(data.x, data.random_walk_pe)[data.train_mask[fold]]
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alunos/Dados/.pyenv/versions/hsnn/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alunos/Dados/.pyenv/versions/hsnn/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alunos/Dados/andre/cooperative-sheaves/neural-sheaf-diffusion/cooperative_sheaves/models/coopshv_model.py", line 248, in forward
    L_in, L_out, L_idx = self.laplacian_builder(to_be_S_maps, to_be_T_maps, c_S, c_T, edge_weights if self.use_edge_weights else None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alunos/Dados/andre/cooperative-sheaves/neural-sheaf-diffusion/cooperative_sheaves/models/coopshv_model.py", line 202, in laplacian_builder
    in_diag_maps = scatter_add((c_T[col].squeeze(0) * edge_weights) ** 2, col, dim=0, dim_size=self.graph_size)[:, None]
                                ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 129.02 GiB. GPU 0 has a total capacity of 23.68 GiB of which 21.76 GiB is free. Including non-PyTorch memory, this process has 1012.00 MiB memory in use. Of the allocated memory 644.58 MiB is allocated by PyTorch, and 61.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
